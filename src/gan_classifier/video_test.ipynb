{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/2of5iN4U+ClQajtSWjwZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeu5407/CGDClassifier/blob/main/src/gan_classifier/video_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VxaPk_aHfDP",
        "outputId": "da4267b7-fba8-4859-90f6-d11d8ecfd6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/github/CGDClassifier/src/cnn_classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9x3W094OjVp",
        "outputId": "353a832e-c059-40a1-9b25-476e7459c1f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/github/CGDClassifier/src/cnn_classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5fTp1U4N6nU",
        "outputId": "62573693-7993-4204-e447-671067530162"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx) (1.15.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.11.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.11.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n",
            "Installing collected packages: onnxruntime\n",
            "Successfully installed onnxruntime-1.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import onnxruntime\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as F\n",
        "import cv2 as cv\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "B3WQAuNaM9_B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_video(video_path, ort_session):\n",
        "\n",
        "    cap = cv.VideoCapture(video_path)\n",
        "    index = 0\n",
        "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "    model_writer = cv.VideoWriter('{}'.format(video_path.replace(\".mp4\",\"_pred.mp4\")), fourcc, 20, (640, 480))\n",
        "    cat_list = ['drink', 'hang', 'lookout', 'phone', 'sleep', 'study', 'study_boring']\n",
        "    index_max = None\n",
        "    result_df = []\n",
        "\n",
        "    def softmax(x):\n",
        "\n",
        "        x = x - np.max(x)\n",
        "        f_x = np.exp(x) / np.sum(np.exp(x))\n",
        "        return f_x\n",
        "\n",
        "    if index_max == None:\n",
        "        index_max = 99999999999\n",
        "\n",
        "    while True:\n",
        "\n",
        "        ret, input_img = cap.read()\n",
        "\n",
        "        if index%100 == 0:\n",
        "          print(\">>> {} Index Save\".format(index))\n",
        "\n",
        "        if not ret or (index == index_max):\n",
        "          print('>>> {} End'.format(os.path.basename(video_path)))\n",
        "          cap.release()\n",
        "          model_writer.release()\n",
        "          cv.destroyAllWindows()\n",
        "          pd.DataFrame(result_df, columns = ['index', 'category', 'drink', 'hang', 'lookout', 'phone', 'sleep', 'study', 'study_boring']).to_csv(\"{}\".format(video_path.replace(\".mp4\",\"_pred.csv\")))\n",
        "          break\n",
        "\n",
        "        image_tensor = F.to_tensor(input_img)\n",
        "        image_tensor = F.resize(image_tensor, (260, 260))\n",
        "        image_tensor = F.normalize(image_tensor, (0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "        image_tensor = image_tensor.unsqueeze(0)\n",
        "\n",
        "        ort_inputs = {ort_session.get_inputs()[0].name : image_tensor.numpy()}\n",
        "        ort_outs = ort_session.run(None, ort_inputs)\n",
        "        pred_list = softmax(ort_outs[0][0]).round(2)\n",
        "        pred = pred_list.argmax()\n",
        "        pred_list = list(pred_list)\n",
        "        pred_per = round(pred_list[int(pred)] * 100, 2)\n",
        "\n",
        "        text1 = 'Index : {}'.format(index)\n",
        "        text2 = 'Outputs : {}'.format(pred_list)\n",
        "        text3 = 'Predict : {}, {}%'.format(cat_list[int(pred)], pred_per)\n",
        "\n",
        "        frame = cv.resize(input_img, (640, 480))\n",
        "        cv.putText(frame, text1, (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255))\n",
        "        cv.putText(frame, text2, (10, 40), cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255))\n",
        "        cv.putText(frame, text3, (10, 60), cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255))\n",
        "\n",
        "        result_list = [index, cat_list[int(pred)]]\n",
        "        result_list.extend(pred_list)\n",
        "        result_df.append(result_list)\n",
        "\n",
        "        model_writer.write(frame)\n",
        "        index += 1"
      ],
      "metadata": {
        "id": "UVfk1WjDOmtL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = glob.glob(os.path.join(os.getcwd().split(os.path.join(\".\",\"src\").replace(\".\",\"\"))[0], \"model\", \"*.onnx\"))[0]\n",
        "video_path_list = glob.glob(os.path.join(os.getcwd().split(os.path.join(\".\",\"src\").replace(\".\",\"\"))[0], \"datasets\", \"test\", \"*.mp4\"))\n",
        "ort_session = onnxruntime.InferenceSession(model_path)\n",
        "\n",
        "for video_path in video_path_list:\n",
        "\n",
        "    print(os.path.basename(video_path))\n",
        "    make_video(video_path, ort_session)"
      ],
      "metadata": {
        "id": "A3J2YiAXM-BH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3cf777-38f2-43a2-c92f-158490147544"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test4.mp4\n",
            ">>> 0 Index Save\n",
            ">>> 100 Index Save\n",
            ">>> 200 Index Save\n",
            ">>> 300 Index Save\n",
            ">>> 400 Index Save\n",
            ">>> 500 Index Save\n",
            ">>> 600 Index Save\n",
            ">>> 700 Index Save\n",
            ">>> 800 Index Save\n",
            ">>> 900 Index Save\n",
            ">>> 1000 Index Save\n",
            ">>> 1100 Index Save\n",
            ">>> 1200 Index Save\n",
            ">>> 1300 Index Save\n",
            ">>> 1400 Index Save\n",
            ">>> 1500 Index Save\n",
            ">>> 1600 Index Save\n",
            ">>> 1700 Index Save\n",
            ">>> 1800 Index Save\n",
            ">>> 1900 Index Save\n",
            ">>> 2000 Index Save\n",
            ">>> 2100 Index Save\n",
            ">>> 2200 Index Save\n",
            ">>> 2300 Index Save\n",
            ">>> 2400 Index Save\n",
            ">>> 2500 Index Save\n",
            ">>> 2600 Index Save\n",
            ">>> 2700 Index Save\n",
            ">>> 2800 Index Save\n",
            ">>> 2900 Index Save\n",
            ">>> 3000 Index Save\n",
            ">>> 3100 Index Save\n",
            ">>> test4.mp4 End\n"
          ]
        }
      ]
    }
  ]
}